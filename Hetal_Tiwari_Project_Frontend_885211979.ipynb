{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Streamlit and Ngrok based front-end for QA system\n",
        "\n",
        "The front end for the RAG question answering system is built using Streamlit and hosted on Ngrok.\n",
        "\n",
        "Streamlit is a free, open-source Python library that allows you to create interactive data apps. It is designed for data scientists and machine learning engineers who want to quickly prototype and share their work.\n",
        "\n",
        "Ngrok is a tool that creates a secure tunnel to a local server running on your machine. This tunnel allows you to expose your local server to the internet, making it accessible from anywhere. Ngrok provides a temporary URL that can be used to access the local server over the internet."
      ],
      "metadata": {
        "id": "MxZnGRE8NjwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing Streamlit\n",
        "!pip install streamlit -q"
      ],
      "metadata": {
        "id": "aYUduXcAzdfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing Ngrok\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFv-ZvXyJdZC",
        "outputId": "916d6b4e-094b-4776-d7dc-51ba25318ac2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Authenticating with ngrok account\n",
        "! ngrok authtoken 2fnpOr4eGPaUCkrY3FPBOAmujye_5fQcqtZ6sCWCTsFLgG5xU"
      ],
      "metadata": {
        "id": "44CLpxQ-L__i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Writing the QA system into a streamlit application as 'app.py'\n",
        "\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "def main():\n",
        "    # Install necessary libraries\n",
        "    os.system(\"pip install haystack-ai\")\n",
        "    os.system(\"pip install datasets>=2.6.1\")\n",
        "    os.system(\"pip install sentence-transformers>=2.2.0\")\n",
        "    os.system(\"pip install accelerate\")\n",
        "    os.system(\"pip install transformers[torch,sentencepiece]\")\n",
        "    os.system(\"pip install google-ai-haystack\")\n",
        "\n",
        "    #Import packages\n",
        "    from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "    from datasets import load_dataset\n",
        "    from haystack import Document\n",
        "    from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "    from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "    from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "    from haystack.components.builders import PromptBuilder\n",
        "    from haystack_integrations.components.generators.google_ai import GoogleAIGeminiGenerator\n",
        "    from haystack import Pipeline\n",
        "\n",
        "     # Set up the Streamlit app\n",
        "    st.set_page_config(page_title=\"My Streamlit App\", page_icon=\":guardsman:\", layout=\"wide\")\n",
        "    st.title(\"Ask a question about the Seven Wonders!\")\n",
        "\n",
        "    # Load the user's API keys from userdata\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAqqiRDjFQsmVZ2hIkR7UMWShx6QVxq_Kc\"\n",
        "    os.environ[\"HF_API_TOKEN\"] = \"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\"\n",
        "\n",
        "    # Initialize components\n",
        "    document_store = InMemoryDocumentStore()\n",
        "    dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
        "    docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
        "    doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    doc_embedder.warm_up()\n",
        "    docs_with_embeddings = doc_embedder.run(docs)\n",
        "    document_store.write_documents(docs_with_embeddings[\"documents\"])\n",
        "    text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    retriever = InMemoryEmbeddingRetriever(document_store)\n",
        "    template = \"\"\"\n",
        "    Given the following information, answer the question.\n",
        "\n",
        "    Context:\n",
        "    {% for document in documents %}\n",
        "        {{ document.content }}\n",
        "    {% endfor %}\n",
        "\n",
        "    Question: {{question}}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    prompt_builder = PromptBuilder(template=template)\n",
        "    generator = GoogleAIGeminiGenerator(model=\"gemini-pro\")\n",
        "\n",
        "   # Create pipeline\n",
        "    pipeline = Pipeline()\n",
        "    pipeline.add_component(\"text_embedder\", text_embedder)\n",
        "    pipeline.add_component(\"retriever\", retriever)\n",
        "    pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
        "    pipeline.add_component(\"llm\", generator)\n",
        "    pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
        "    pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
        "    pipeline.connect(\"prompt_builder\", \"llm\")\n",
        "\n",
        "    # Create a text input for the user to ask a question\n",
        "    question = st.text_input(\"Ask a question:\")\n",
        "\n",
        "    # Create a button to submit the question\n",
        "    if st.button(\"Submit\"):\n",
        "        # Display the answer\n",
        "        response = ask_question(pipeline, question)\n",
        "        st.write(\"Answer:\", response)\n",
        "\n",
        "\n",
        "def ask_question(pipeline, question):\n",
        "    response = pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
        "    answer = response[\"llm\"][\"replies\"][0]\n",
        "    return answer\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Prx-mBb5Rf",
        "outputId": "f04ba704-7c18-4ceb-c837-dd0dbbb63f2b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to run the streamlit app\n",
        "def run_streamlit():\n",
        "    os.system('streamlit run app.py --server.port 8501')"
      ],
      "metadata": {
        "id": "-KzaaPYCMd1X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "import os\n",
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "WZUFXBx4Mik4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open a tunnel to the streamlit port 8501\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)\n",
        "print('Your Streamlit app is live at:', public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HLUePdmMody",
        "outputId": "6129816f-fb2c-4e61-a602-e93d320c7c1e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Streamlit app is live at: NgrokTunnel: \"https://4fa9-34-87-105-198.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kill the ngrok session\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "jw96BCjgMyv7"
      },
      "execution_count": 35,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}